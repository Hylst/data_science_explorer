/**
 * Machine Learning Algorithms and Concepts
 * Core ML algorithms, techniques, and methodologies
 */

import { GlossaryEntry } from './types';

export const machineLearningTerms: GlossaryEntry[] = [
  {
    term: "Machine Learning",
    description: "Le Machine Learning est comme enseigner à un ordinateur à reconnaître des patterns, à la manière dont un enfant apprend à distinguer les chiens des chats en voyant de nombreux exemples. Contrairement à la programmation traditionnelle où nous écrivons des règles explicites, le ML permet aux machines de **découvrir automatiquement** ces règles à partir des données. **Définition formelle** : sous-domaine de l'IA qui développe des algorithmes capables d'améliorer leurs performances sur une tâche spécifique grâce à l'expérience (données). **Les trois piliers** : 1) **Données** (le carburant), 2) **Algorithmes** (le moteur), 3) **Puissance de calcul** (l'accélérateur). **Applications omniprésentes** : recommandations Netflix, reconnaissance vocale Siri, détection de spam, voitures autonomes, diagnostic médical. **Révolution historique** : passage de 'programmer des solutions' à 'apprendre des solutions'. **Types principaux** : supervisé (avec exemples étiquetés), non-supervisé (découverte de structures cachées), par renforcement (apprentissage par essai-erreur). Le ML transforme notre rapport à la résolution de problèmes complexes en automatisant la découverte de patterns dans des volumes de données impossibles à traiter manuellement.",
    category: "machine-learning",
    icon: "Cpu"
  },
  {
    term: "Classification",
    description: "La classification est comme un système de tri automatique qui apprend à catégoriser des éléments, à l'image d'un bibliothécaire qui range les livres par genre après avoir appris les caractéristiques de chaque catégorie. **Objectif** : prédire la classe ou catégorie d'appartenance d'une nouvelle observation basée sur ses caractéristiques. **Types** : binaire (2 classes : spam/non-spam), multi-classe (plusieurs catégories : chien/chat/oiseau), multi-label (plusieurs étiquettes simultanées). **Processus** : 1) Entraînement sur des exemples étiquetés, 2) Apprentissage des frontières de décision, 3) Prédiction sur nouvelles données. **Algorithmes populaires** : arbres de décision (interprétables), SVM (efficaces haute dimension), Random Forest (robustes), réseaux de neurones (patterns complexes), Naive Bayes (texte). **Applications concrètes** : diagnostic médical (maladie/sain), reconnaissance d'images (objets), analyse de sentiment (positif/négatif), détection de fraude. **Métriques d'évaluation** : accuracy, précision, rappel, F1-score. **Défis** : classes déséquilibrées, overfitting, interprétabilité. La classification transforme des données brutes en décisions catégorielles exploitables.",
    category: "machine-learning",
    icon: "Target"
  },
  {
    term: "Apprentissage Supervisé",
    description: "L'apprentissage supervisé fonctionne comme un étudiant qui apprend avec un professeur : l'algorithme dispose d'exemples avec les 'bonnes réponses' pour apprendre à généraliser. **Principe fondamental** : utiliser des données étiquetées (input-output pairs) pour entraîner un modèle capable de prédire les sorties pour de nouvelles entrées. **Analogie** : apprendre les mathématiques avec un manuel de corrections - on voit le problème ET la solution. **Deux grandes familles** : 1) **Classification** (prédire des catégories discrètes), 2) **Régression** (prédire des valeurs continues). **Processus d'apprentissage** : 1) Entraînement (learning phase), 2) Validation (tuning phase), 3) Test (evaluation phase). **Avantages** : performance généralement élevée, métriques d'évaluation claires, large choix d'algorithmes. **Inconvénients** : nécessite des données étiquetées (coûteuses), risque d'overfitting, biais des labels. **Applications** : reconnaissance d'images, traduction automatique, prédiction de prix, diagnostic médical. **Différence clé** : contrairement à l'apprentissage non-supervisé, on connaît la 'vérité terrain' pendant l'entraînement, permettant une optimisation dirigée vers un objectif précis.",
    category: "machine-learning",
    icon: "Users"
  },
  {
    term: "Apprentissage Non Supervisé",
    description: "L'apprentissage non supervisé fonctionne comme un explorateur qui découvre des territoires inconnus sans carte ni guide : l'algorithme doit identifier des structures et patterns cachés dans des données sans 'bonnes réponses' préalables. **Principe fondamental** : extraire des informations significatives de données brutes non étiquetées pour révéler l'organisation naturelle sous-jacente. **Analogie** : un archéologue qui classe des artefacts par similarité sans connaître leur époque - il découvre des groupes naturels par observation. **Trois missions principales** : 1) **Clustering** (regrouper les similaires), 2) **Réduction de dimensionnalité** (simplifier la complexité), 3) **Détection d'anomalies** (identifier l'inhabituel). **Avantages** : pas besoin de données étiquetées (coûteuses), découverte de patterns inattendus, exploration de données massives. **Défis** : évaluation difficile (pas de vérité terrain), interprétation subjective, choix du nombre de clusters. **Applications concrètes** : segmentation client (marketing), compression d'images, détection de fraudes, analyse génomique. **Algorithmes populaires** : K-means (partitionnement), PCA (réduction dimensionnelle), DBSCAN (densité), t-SNE (visualisation). **Différence clé** : contrairement au supervisé, on ne sait pas ce qu'on cherche - on laisse les données révéler leurs secrets naturels.",
    category: "machine-learning",
    icon: "Search"
  },
  {
    term: "Clustering",
    description: "Le clustering fonctionne comme un organisateur de fête qui regroupe les invités par affinités naturelles sans connaître leurs relations à l'avance : l'algorithme identifie automatiquement des groupes homogènes dans des données non étiquetées. **Objectif** : partitionner un ensemble de données en clusters où les éléments intra-cluster sont similaires et les éléments inter-clusters sont différents. **Analogie** : trier automatiquement une bibliothèque désorganisée en regroupant les livres par thème sans lire les étiquettes. **Types principaux** : 1) **Partitionnement** (K-means, K-medoids), 2) **Hiérarchique** (agglomératif, divisif), 3) **Basé sur la densité** (DBSCAN, OPTICS), 4) **Basé sur la distribution** (Gaussian Mixture). **Métriques de distance** : euclidienne (géométrique), Manhattan (grille urbaine), cosinus (orientation), Jaccard (ensembles). **Applications concrètes** : segmentation client (marketing), compression d'images, analyse génomique, détection de communautés sociales, organisation de documents. **Défis** : choix du nombre de clusters (K), sensibilité aux outliers, formes non-sphériques, dimensionnalité élevée. **Évaluation** : silhouette score, inertie intra-cluster, Davies-Bouldin index. **Avantage clé** : révèle la structure naturelle des données sans supervision préalable, permettant des insights inattendus.",
    category: "machine-learning",
    icon: "Layers"
  },
  {
    term: "Overfitting (Surapprentissage)",
    description: "L'overfitting est comme un étudiant qui mémorise par cœur les exercices du manuel sans comprendre les concepts : excellent sur les exercices connus, mais incapable de résoudre de nouveaux problèmes. **Définition** : le modèle apprend trop spécifiquement les détails et le bruit des données d'entraînement, perdant sa capacité de généralisation. **Symptômes** : performance excellente sur l'entraînement (>95%) mais médiocre sur la validation (<70%). **Causes principales** : modèle trop complexe, données d'entraînement insuffisantes, entraînement trop long, absence de régularisation. **Analogie visuelle** : une courbe qui passe exactement par tous les points d'entraînement, y compris les aberrations. **Solutions** : 1) **Régularisation** (L1, L2, Dropout), 2) **Early stopping**, 3) **Cross-validation**, 4) **Plus de données**, 5) **Réduction de complexité**. **Détection** : courbes d'apprentissage divergentes (train vs validation). **Impact** : modèles inutilisables en production car non-généralisables. **Équilibre crucial** : trouver le sweet spot entre sous-apprentissage et sur-apprentissage via le bias-variance tradeoff.",
    category: "machine-learning",
    icon: "AlertTriangle"
  },
  {
    term: "Underfitting (Sous-apprentissage)",
    description: "L'underfitting est comme un étudiant qui n'a pas assez étudié : il échoue aussi bien aux exercices du manuel qu'aux nouveaux problèmes par manque de compréhension fondamentale. **Définition** : le modèle est trop simple pour capturer la structure sous-jacente et les patterns complexes des données. **Symptômes** : performances médiocres tant sur l'entraînement que sur la validation (toutes deux faibles et similaires). **Causes principales** : modèle trop simple, features insuffisantes, régularisation excessive, entraînement insuffisant. **Analogie visuelle** : une ligne droite tentant de modéliser une courbe complexe. **Diagnostic** : 1) Accuracy faible sur train ET test, 2) Courbes d'apprentissage plates, 3) Résidus avec patterns visibles. **Solutions** : 1) **Augmenter la complexité** (plus de paramètres, couches), 2) **Feature engineering** (nouvelles variables), 3) **Réduire la régularisation**, 4) **Algorithmes plus sophistiqués**, 5) **Entraînement plus long**. **Paradoxe** : plus facile à détecter que l'overfitting mais parfois négligé. **Équilibre** : l'underfitting est le point de départ - on augmente progressivement la complexité jusqu'à atteindre l'optimum avant l'overfitting.",
    category: "machine-learning",
    icon: "TrendingDown"
  },
  {
    term: "Cross-Validation",
    description: "La cross-validation fonctionne comme un examen médical complet où plusieurs spécialistes examinent le patient sous différents angles pour obtenir un diagnostic fiable : l'algorithme teste le modèle sur plusieurs échantillons différents pour évaluer sa performance réelle. **Principe** : diviser les données en k 'plis' (folds), utiliser k-1 plis pour l'entraînement et 1 pli pour la validation, répéter k fois en changeant le pli de validation. **Analogie** : comme tester un étudiant sur 5 examens différents plutôt qu'un seul pour évaluer son niveau réel. **Types principaux** : 1) **K-fold** (division équitable), 2) **Stratified** (préserve les proportions de classes), 3) **Leave-One-Out** (LOOCV, k=n), 4) **Time Series** (respecte l'ordre temporel). **Avantages** : estimation robuste des performances, détection d'overfitting, utilisation optimale des données, réduction de la variance. **Métriques** : moyenne et écart-type des scores sur les k plis. **Applications** : sélection de modèles, tuning d'hyperparamètres, estimation de performance en production. **Coût** : k fois plus d'entraînements, mais investissement crucial pour la fiabilité. **Règle d'or** : k=5 ou k=10 pour un bon compromis biais-variance-coût computationnel.",
    category: "machine-learning",
    icon: "CheckCircle"
  },
  {
    term: "Random Forest",
    description: "Random Forest fonctionne comme un conseil de sages où chaque expert (arbre) donne son avis sur une partie différente du problème, et la décision finale émerge du consensus collectif. **Principe** : construire une 'forêt' de nombreux arbres de décision entraînés sur des échantillons différents des données, puis agréger leurs prédictions. **Double randomisation** : 1) **Bootstrap sampling** (échantillons aléatoires avec remise), 2) **Feature bagging** (sous-ensemble aléatoire de variables à chaque nœud). **Avantages majeurs** : résistance à l'overfitting, gestion des valeurs manquantes, importance des variables, parallélisation naturelle, performance robuste sans tuning intensif. **Mécanisme de vote** : classification (majorité), régression (moyenne). **Applications** : finance (scoring crédit), médecine (diagnostic), écologie (prédiction espèces), e-commerce (recommandations). **Hyperparamètres clés** : nombre d'arbres (n_estimators), profondeur max, features par split. **Interprétabilité** : feature importance, partial dependence plots, SHAP values. **Comparaison** : plus robuste qu'un arbre unique, plus interprétable que les réseaux de neurones, souvent baseline de référence. **Inventeur** : Leo Breiman (2001), révolution dans l'apprentissage d'ensemble.",
    category: "machine-learning",
    icon: "TreePine"
  },
  {
    term: "Support Vector Machine (SVM)",
    description: "SVM fonctionne comme un arbitre qui trace la ligne de démarcation la plus équitable entre deux équipes sur un terrain : il trouve l'hyperplan optimal qui sépare les classes en maximisant la 'zone de sécurité' (marge). **Principe géométrique** : identifier la frontière de décision qui maximise la distance aux points les plus proches de chaque classe (support vectors). **Analogie** : construire une autoroute avec la bande d'arrêt d'urgence la plus large possible entre deux villes. **Innovation clé** : le **kernel trick** transforme des problèmes non-linéaires en problèmes linéaires dans un espace de dimension supérieure. **Types de kernels** : linéaire (séparation droite), polynomial (courbes), RBF/Gaussien (formes complexes), sigmoïde (réseaux de neurones). **Avantages** : efficace en haute dimension, mémoire économique (seuls les support vectors), versatile (kernels), robuste aux outliers. **Applications** : classification de texte, reconnaissance d'images, bioinformatique, détection de fraudes. **Hyperparamètres** : C (régularisation), gamma (influence des points), kernel choice. **Défis** : sensible à l'échelle des features, pas de probabilités directes, choix du kernel. **Inventeurs** : Vapnik & Cortes (1995), fondement théorique solide (théorie de Vapnik-Chervonenkis).",
    category: "machine-learning",
    icon: "Divide"
  },
  {
    term: "Hyperparameter Tuning",
    description: "L'hyperparameter tuning fonctionne comme un chef cuisinier qui ajuste la température du four, le temps de cuisson et les épices pour perfectionner sa recette : on optimise les 'réglages' de l'algorithme qui ne sont pas appris automatiquement. **Différence clé** : contrairement aux paramètres (appris des données), les hyperparamètres sont des configurations externes qui contrôlent l'apprentissage. **Analogie** : régler une radio pour capter la meilleure fréquence - les stations (patterns) existent, mais il faut trouver les bons réglages. **Exemples d'hyperparamètres** : learning rate (vitesse d'apprentissage), nombre d'arbres (Random Forest), profondeur max (arbres), regularization strength (pénalité). **Techniques d'optimisation** : 1) **Grid Search** (exhaustif mais coûteux), 2) **Random Search** (efficace, exploration large), 3) **Bayesian Optimization** (intelligent, utilise l'historique), 4) **Hyperband** (early stopping adaptatif). **Processus** : définir l'espace de recherche → évaluer via cross-validation → sélectionner la meilleure combinaison. **Défis** : explosion combinatoire, coût computationnel, overfitting sur la validation. **Impact** : différence entre un modèle médiocre et excellent, souvent 10-20% d'amélioration. **Automatisation** : AutoML révolutionne ce processus fastidieux mais crucial.",
    category: "machine-learning",
    icon: "Settings"
  },
  {
    term: "Ensemble Methods",
    description: "Les méthodes d'ensemble fonctionnent comme un jury de spécialistes où chaque expert apporte son expertise unique, et la décision collective surpasse celle de n'importe quel expert individuel. **Principe fondamental** : 'la sagesse des foules' - combiner plusieurs modèles faibles pour créer un prédicteur fort et robuste. **Analogie** : un orchestre symphonique où chaque musicien (modèle) joue sa partition, créant une harmonie (prédiction) plus riche que tout solo. **Trois stratégies principales** : 1) **Bagging** (Bootstrap Aggregating) - entraîner en parallèle sur différents échantillons, 2) **Boosting** - entraîner séquentiellement en corrigeant les erreurs, 3) **Stacking** - méta-modèle qui apprend à combiner les prédictions. **Algorithmes populaires** : Random Forest (bagging), XGBoost/AdaBoost (boosting), Voting Classifier (combinaison simple). **Avantages** : réduction de l'overfitting, amélioration de la généralisation, robustesse aux outliers, capture de patterns complémentaires. **Applications** : compétitions Kaggle (dominance), systèmes critiques (médecine, finance), recommandations (Netflix). **Théorie** : réduction simultanée du biais et de la variance. **Défis** : complexité computationnelle, interprétabilité réduite, risque de sur-complexification. **Impact** : révolution dans les performances ML, standard dans l'industrie.",
    category: "machine-learning",
    icon: "Layers"
  },
  {
    term: "AutoML",
    description: "AutoML fonctionne comme un chef cuisinier expert qui automatise toute la préparation d'un repas : de la sélection des ingrédients (features) à la cuisson optimale (hyperparamètres), libérant le client de la complexité technique. **Vision** : démocratiser le Machine Learning en automatisant les tâches expertes traditionnellement réservées aux data scientists. **Analogie** : passer de la cuisine manuelle (ML traditionnel) à un robot culinaire intelligent qui optimise automatiquement chaque étape. **Processus automatisé** : 1) **Data preprocessing** (nettoyage, encodage), 2) **Feature engineering** (création, sélection), 3) **Model selection** (algorithmes), 4) **Hyperparameter tuning** (optimisation), 5) **Model evaluation** (validation). **Technologies clés** : Neural Architecture Search (NAS), Bayesian Optimization, Genetic Algorithms, Meta-learning. **Plateformes populaires** : Google AutoML, H2O.ai, Auto-sklearn, TPOT, DataRobot. **Avantages** : accessibilité (non-experts), rapidité (prototypage), performance (optimisation exhaustive), reproductibilité. **Limitations** : boîte noire, coût computationnel, manque de contrôle fin, domaines spécialisés. **Impact** : révolution de l'accessibilité ML, accélération du time-to-market, démocratisation de l'IA pour les entreprises.",
    category: "machine-learning",
    icon: "Settings"
  },
  {
    term: "Explainable AI (XAI)",
    description: "L'Explainable AI fonctionne comme un médecin qui doit justifier son diagnostic : au lieu de dire simplement 'vous êtes malade', il explique les symptômes, analyses et raisonnements qui l'ont mené à cette conclusion. **Enjeu crucial** : transformer les 'boîtes noires' de l'IA en systèmes transparents et compréhensibles pour les humains. **Analogie** : passer d'un oracle mystérieux qui donne des réponses sans explication à un professeur qui détaille sa démarche. **Motivations** : 1) **Confiance** (acceptation utilisateur), 2) **Réglementation** (RGPD, secteurs critiques), 3) **Débogage** (amélioration modèles), 4) **Éthique** (biais, équité), 5) **Responsabilité** (décisions critiques). **Techniques principales** : LIME (approximation locale), SHAP (valeurs de Shapley), attention mechanisms (réseaux de neurones), feature importance (arbres), counterfactuals (scénarios alternatifs). **Types d'explications** : globales (comportement général), locales (prédiction spécifique), par exemple (cas similaires). **Applications critiques** : médecine (diagnostic), justice (sentences), finance (crédit), recrutement (sélection). **Défi** : équilibre entre performance et interprétabilité - les modèles les plus précis sont souvent les moins explicables. **Impact** : démocratisation de l'IA, acceptation sociale, conformité réglementaire.",
    category: "machine-learning",
    icon: "Lightbulb"
  },
  {
    term: "Reinforcement Learning",
    description: "Le Reinforcement Learning fonctionne comme l'apprentissage d'un enfant qui découvre le monde par essais-erreurs : l'agent apprend les meilleures actions en recevant des récompenses ou punitions de son environnement. **Paradigme** : pas de données étiquetées, mais un système de feedback (reward/penalty) qui guide l'apprentissage optimal. **Analogie** : dresser un animal avec des friandises - l'animal apprend quels comportements maximisent les récompenses. **Composants clés** : 1) **Agent** (apprenant), 2) **Environnement** (monde), 3) **Actions** (choix possibles), 4) **États** (situations), 5) **Récompenses** (feedback). **Processus** : observation → action → récompense → mise à jour de la politique → répétition. **Algorithmes majeurs** : Q-Learning (valeurs d'actions), Policy Gradient (politiques directes), Actor-Critic (hybride), Deep Q-Networks (DQN). **Applications révolutionnaires** : jeux (AlphaGo, StarCraft), robotique (manipulation), finance (trading), véhicules autonomes, recommandations personnalisées. **Défis** : exploration vs exploitation, récompenses parses, stabilité d'entraînement, généralisation. **Avantage unique** : apprend des stratégies optimales sans exemples préalables, juste par interaction et expérimentation. **Impact** : révolution dans l'IA autonome et la prise de décision séquentielle.",
    category: "machine-learning",
    icon: "Target"
  },
  // Specific Algorithms
  {
    term: "Régression linéaire (Linear Regression)",
    description: "La régression linéaire fonctionne comme tracer la meilleure ligne droite à travers un nuage de points pour prédire de nouvelles valeurs : elle modélise la relation entre variables par une équation mathématique simple. **Principe** : trouver la droite y = ax + b qui minimise l'erreur entre les prédictions et les vraies valeurs. **Analogie** : comme estimer le prix d'une maison selon sa surface - plus elle est grande, plus elle coûte cher, selon une relation approximativement linéaire. **Méthode des moindres carrés** : minimise la somme des carrés des résidus (distances verticales aux points). **Hypothèses clés** : 1) **Linéarité** (relation droite), 2) **Indépendance** (observations non corrélées), 3) **Homoscédasticité** (variance constante), 4) **Normalité** des résidus. **Extensions** : régression multiple (plusieurs variables), polynomiale (courbes), régularisée (Ridge, Lasso). **Avantages** : simplicité, interprétabilité, rapidité, pas d'hyperparamètres. **Limitations** : relations non-linéaires, sensibilité aux outliers, multicolinéarité. **Applications** : prédiction de prix, analyse de tendances, économétrie, sciences sociales. **Évaluation** : R², RMSE, MAE. **Fondement** : base de nombreux algorithmes plus complexes, premier modèle à maîtriser.",
    category: "machine-learning",
    icon: "LineChart"
  },
  {
    term: "Régression logistique (Logistic Regression)",
    description: "La régression logistique fonctionne comme un interrupteur intelligent qui calcule la probabilité qu'un événement se produise : au lieu de prédire une valeur continue, elle estime la chance qu'une observation appartienne à une classe. **Principe** : utilise la fonction sigmoïde pour transformer n'importe quelle valeur en probabilité entre 0 et 1. **Analogie** : comme un médecin qui évalue la probabilité qu'un patient ait une maladie selon ses symptômes - pas juste 'oui/non' mais '75% de chances'. **Fonction logistique** : courbe en S qui 'écrase' les valeurs extrêmes vers 0 ou 1, évitant les prédictions impossibles (<0 ou >1). **Processus** : 1) Combinaison linéaire des features, 2) Transformation par sigmoïde, 3) Seuil de décision (généralement 0.5). **Avantages** : probabilités calibrées, pas d'hypothèses sur la distribution, robuste aux outliers, interprétable (odds ratios). **Extensions** : multinomiale (>2 classes), ordinale (classes ordonnées), régularisée (L1/L2). **Applications** : diagnostic médical, marketing (achat/non-achat), spam detection, A/B testing. **Évaluation** : accuracy, précision/rappel, AUC-ROC, log-loss. **Différence clé** : contrairement à la régression linéaire, prédit des probabilités, pas des valeurs continues. **Fondement** : base de nombreux algorithmes de classification modernes.",
    category: "machine-learning",
    icon: "Target"
  },
  {
    term: "k-plus proches voisins (k-Nearest Neighbors - k-NN)",
    description: "k-NN fonctionne comme demander conseil à ses voisins les plus proches : pour prendre une décision, on regarde ce que font les k personnes les plus similaires dans notre entourage et on suit la majorité. **Principe** : 'dis-moi qui sont tes voisins, je te dirai qui tu es' - classification basée sur la proximité dans l'espace des features. **Analogie** : déménager dans un nouveau quartier et deviner le parti politique dominant en regardant les panneaux des 5 maisons les plus proches. **Processus** : 1) Calculer la distance à tous les points d'entraînement, 2) Sélectionner les k plus proches, 3) Vote majoritaire (classification) ou moyenne (régression). **Métriques de distance** : euclidienne (géométrique), Manhattan (grille urbaine), Minkowski (généralisation), Hamming (catégorielles). **Choix de k** : k petit (sensible au bruit), k grand (lisse mais peut ignorer les patterns locaux). **Avantages** : simplicité conceptuelle, pas d'hypothèses sur les données, adaptatif aux patterns locaux, fonctionne avec données non-linéaires. **Inconvénients** : coûteux en prédiction (O(n)), sensible à la dimensionnalité (curse of dimensionality), nécessite normalisation des features. **Applications** : systèmes de recommandation, reconnaissance de formes, détection d'anomalies. **Optimisations** : structures d'indexation (KD-tree, Ball-tree), approximations (LSH).",
    category: "machine-learning",
    icon: "Users"
  },
  {
    term: "Arbres de décision (Decision Trees)",
    description: "Les arbres de décision fonctionnent comme un questionnaire médical où chaque question mène à la suivante selon la réponse, jusqu'à arriver au diagnostic final : l'algorithme pose une série de questions binaires pour classifier ou prédire. **Structure** : racine (première question), nœuds internes (questions), feuilles (décisions finales). **Analogie** : comme le jeu '20 questions' où on devine un objet en posant des questions oui/non optimales. **Construction** : 1) Choisir la meilleure question (feature + seuil), 2) Diviser les données, 3) Répéter récursivement sur chaque branche. **Critères de division** : Gini impurity (classification), entropie (information gain), MSE (régression) - on cherche à maximiser la 'pureté' des groupes. **Avantages majeurs** : interprétabilité totale (règles if-then), gestion automatique des interactions, pas de preprocessing, robuste aux outliers, gère les données manquantes. **Inconvénients** : instabilité (petits changements → arbres différents), overfitting facile, biais vers features avec plus de valeurs. **Techniques de régularisation** : profondeur max, nombre min d'échantillons par feuille, pruning (élagage). **Applications** : diagnostic médical, scoring crédit, systèmes experts, analyse exploratoire. **Extensions** : Random Forest (ensemble), Gradient Boosting (séquentiel). **Visualisation** : graphiques intuitifs, règles explicites.",
    category: "machine-learning",
    icon: "TreePine"
  },
  {
    term: "Boosting de gradient (Gradient Boosting)",
    description: "Le Gradient Boosting fonctionne comme une équipe de correcteurs qui travaillent en séquence : chaque nouveau correcteur se concentre spécifiquement sur les erreurs laissées par ses prédécesseurs, créant progressivement une solution de plus en plus précise. **Principe révolutionnaire** : au lieu d'entraîner des modèles indépendamment (comme Random Forest), on construit une chaîne de modèles faibles où chacun apprend des erreurs du précédent. **Analogie** : comme un étudiant qui refait un examen en se concentrant uniquement sur les questions qu'il a ratées la première fois. **Processus itératif** : 1) Modèle initial (souvent une simple moyenne), 2) Calcul des résidus (erreurs), 3) Nouveau modèle pour prédire ces résidus, 4) Ajout pondéré à l'ensemble, 5) Répétition. **Gradient descent** : optimise une fonction de perte en suivant la direction de plus forte diminution de l'erreur. **Algorithmes populaires** : XGBoost (eXtreme), LightGBM (Microsoft), CatBoost (Yandex), scikit-learn GradientBoosting. **Avantages** : performance exceptionnelle, gestion des données manquantes, feature importance, flexibilité (classification/régression). **Hyperparamètres clés** : learning rate (vitesse d'apprentissage), n_estimators (nombre d'itérations), max_depth (complexité des arbres). **Applications dominantes** : compétitions Kaggle, finance (scoring), publicité (CTR), e-commerce. **Risques** : overfitting (contrôlé par early stopping), sensibilité aux hyperparamètres, temps d'entraînement. **Impact** : révolution des performances ML, standard industriel pour les données tabulaires.",
    category: "machine-learning",
    icon: "TrendingUp"
  },
  {
    term: "Clustering k-moyennes (k-Means Clustering)",
    description: "K-Means fonctionne comme un organisateur de soirée qui doit répartir les invités en k groupes de tables où chaque personne se sent le plus à l'aise possible avec ses voisins de table. **Principe** : partitionner n observations en k clusters où chaque observation appartient au cluster dont le centroïde (centre) est le plus proche. **Analogie géographique** : comme diviser une ville en k quartiers où chaque maison est rattachée au centre commercial le plus proche. **Algorithme itératif** : 1) **Initialisation** (placer k centroïdes aléatoirement), 2) **Assignation** (chaque point rejoint le centroïde le plus proche), 3) **Mise à jour** (recalculer les centroïdes comme moyenne des points assignés), 4) **Répétition** jusqu'à convergence. **Fonction objectif** : minimiser la somme des carrés intra-cluster (WCSS - Within-Cluster Sum of Squares). **Choix de k** : méthode du coude (elbow method), silhouette score, gap statistic. **Avantages** : simplicité conceptuelle, efficacité computationnelle O(nkt), garantie de convergence, parallélisable. **Limitations** : nécessite de spécifier k à l'avance, sensible à l'initialisation (k-means++), assume des clusters sphériques, sensible aux outliers et à l'échelle des variables. **Applications** : segmentation client, compression d'images, préprocessing, analyse de marché. **Variantes** : k-means++, mini-batch k-means, fuzzy c-means. **Preprocessing crucial** : normalisation des features, gestion des outliers.",
    category: "machine-learning",
    icon: "Layers"
  },
  {
    term: "Clustering hiérarchique (Hierarchical Clustering)",
    description: "**L'arbre généalogique des données !** Comme construire un arbre familial qui montre comment les individus se regroupent en familles, puis en clans, puis en tribus - le clustering hiérarchique révèle la structure naturelle d'imbrication des groupes dans les données.\n\n**🌳 Analogie Généalogique :**\nImaginez reconstituer l'arbre généalogique de l'humanité : on peut partir des individus et les regrouper progressivement (agglomératif) ou partir de l'humanité entière et la diviser progressivement (divisif).\n\n**🎯 Deux Approches Fondamentales :**\n\n**🔼 Agglomératif (Bottom-Up) - Le Plus Populaire :**\n• **Départ** : Chaque point = un cluster individuel\n• **Processus** : Fusionner itérativement les clusters les plus proches\n• **Fin** : Un seul cluster contenant tous les points\n• **Avantage** : Plus stable et déterministe\n\n**🔽 Divisif (Top-Down) - Plus Rare :**\n• **Départ** : Tous les points dans un seul cluster\n• **Processus** : Diviser itérativement les clusters les plus hétérogènes\n• **Fin** : Chaque point dans son propre cluster\n• **Avantage** : Efficace si on veut peu de clusters\n\n**📏 Métriques de Distance :**\n\n**Entre Points :**\n- **Euclidienne** : Distance géométrique classique\n- **Manhattan** : Distance en 'blocs de ville'\n- **Cosinus** : Angle entre vecteurs (orientation)\n- **Hamming** : Différences pour données catégorielles\n\n**Entre Clusters (Linkage) :**\n- **Single** : Distance minimale entre points des clusters\n- **Complete** : Distance maximale entre points des clusters\n- **Average** : Distance moyenne entre tous les points\n- **Ward** : Minimise la variance intra-cluster\n\n**🌲 Le Dendrogramme - Visualisation Magique :**\n\n```\n    Dendrogramme\n        │\n    ┌───┴───┐\n    │       │\n  ┌─┴─┐   ┌─┴─┐\n  │   │   │   │\n  A   B   C   D\n```\n\n**Lecture** : Plus la fusion est haute, plus les clusters sont différents\n**Coupe** : Ligne horizontale = nombre de clusters souhaité\n**Hauteur** : Indique la dissimilarité au moment de la fusion\n\n**⚡ Avantages Uniques :**\n\n**Pas de K Prédéfini :**\n- **Flexibilité** : Explore tous les nombres de clusters possibles\n- **Dendrogramme** : Visualisation complète de la structure\n- **Décision Post-hoc** : Choix du nombre optimal après analyse\n\n**Structure Révélée :**\n- **Hiérarchie Naturelle** : Groupes, sous-groupes, sous-sous-groupes\n- **Clusters Imbriqués** : Relations entre différents niveaux\n- **Stabilité** : Résultats reproductibles (agglomératif)\n\n**Interprétabilité :**\n- **Processus Transparent** : Chaque étape de fusion visible\n- **Justification** : Pourquoi certains points sont groupés\n- **Exploration** : Navigation dans différents niveaux de granularité\n\n**⚠️ Limitations et Défis :**\n\n**Complexité Computationnelle :**\n- **Temps** : O(n³) pour l'algorithme naïf\n- **Mémoire** : O(n²) pour stocker la matrice de distances\n- **Scalabilité** : Difficile avec >10,000 points\n\n**Sensibilités :**\n- **Outliers** : Points aberrants peuvent créer des clusters artificiels\n- **Échelle** : Variables avec grandes valeurs dominent\n- **Forme** : Assume des clusters compacts (sauf single linkage)\n\n**Choix Critiques :**\n- **Métrique de Distance** : Impact majeur sur les résultats\n- **Linkage Criterion** : Détermine la forme des clusters\n- **Nombre de Clusters** : Subjectif malgré les métriques\n\n**🛠️ Implémentation Pratique :**\n\n```python\nfrom scipy.cluster.hierarchy import dendrogram, linkage, fcluster\nfrom sklearn.cluster import AgglomerativeClustering\nimport matplotlib.pyplot as plt\n\n# Clustering hiérarchique\nlinkage_matrix = linkage(data, method='ward')\n\n# Visualisation du dendrogramme\ndendrogram(linkage_matrix)\nplt.show()\n\n# Extraction des clusters\nclusters = fcluster(linkage_matrix, t=3, criterion='maxclust')\n```\n\n**🎯 Applications Optimales :**\n\n**Biologie et Médecine :**\n- **Phylogénie** : Arbres évolutionnaires des espèces\n- **Génomique** : Classification des gènes par fonction\n- **Épidémiologie** : Propagation de maladies\n\n**Sciences Sociales :**\n- **Sociologie** : Groupes sociaux et communautés\n- **Psychologie** : Classification des personnalités\n- **Linguistique** : Familles de langues\n\n**Business et Marketing :**\n- **Segmentation Client** : Hiérarchie de segments\n- **Analyse Concurrentielle** : Groupes de concurrents\n- **Organisation** : Structure hiérarchique optimale\n\n**📊 Métriques d'Évaluation :**\n\n**Cohésion Interne :**\n- **Silhouette Score** : Qualité globale du clustering\n- **Calinski-Harabasz** : Ratio variance inter/intra\n- **Davies-Bouldin** : Compacité et séparation\n\n**Stabilité :**\n- **Cophenetic Correlation** : Fidélité du dendrogramme\n- **Bootstrap** : Robustesse aux variations d'échantillon\n\n**💡 Stratégies d'Optimisation :**\n\n**Preprocessing :**\n- **Normalisation** : StandardScaler, MinMaxScaler\n- **Réduction Dimensionnelle** : PCA avant clustering\n- **Outlier Detection** : Isolation Forest, Z-score\n\n**Choix Algorithmiques :**\n- **Ward** : Clusters compacts et équilibrés\n- **Complete** : Clusters compacts mais peut créer des chaînes\n- **Average** : Compromis entre single et complete\n- **Single** : Détecte les formes allongées mais sensible au bruit\n\n**🚀 Variantes Avancées :**\n\n**BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies) :**\n- **Scalabilité** : Gère de très gros datasets\n- **Mémoire** : Structure d'arbre compacte\n- **Streaming** : Traitement de données en flux\n\n**Clustering Hiérarchique Flou :**\n- **Appartenance Partielle** : Points peuvent appartenir à plusieurs clusters\n- **Incertitude** : Quantification de l'ambiguïté\n\n**📈 Exemple Concret - E-commerce :**\n\n**Contexte** : Segmentation de 50,000 clients d'un site e-commerce\n\n**Variables** : Fréquence d'achat, montant moyen, ancienneté, catégories préférées\n\n**Processus** :\n1. **Preprocessing** : Normalisation, gestion des outliers\n2. **Clustering** : Ward linkage sur distance euclidienne\n3. **Dendrogramme** : Révèle 5 segments naturels\n4. **Validation** : Silhouette score = 0.73\n\n**Résultats** :\n- **VIP** (2%) : Gros acheteurs fidèles\n- **Réguliers** (15%) : Achats fréquents, montants moyens\n- **Occasionnels** (35%) : Achats saisonniers\n- **Nouveaux** (25%) : Récents, potentiel incertain\n- **Dormants** (23%) : Inactifs, à réactiver\n\n**Impact Business** : +25% ROI marketing grâce au ciblage personnalisé\n\n**🎯 Règles de Décision :**\n- **< 1,000 points** → Hiérarchique (exploration complète)\n- **> 10,000 points** → K-means puis hiérarchique sur centroïdes\n- **Structure inconnue** → Hiérarchique pour découverte\n- **K connu** → K-means plus efficace\n- **Interprétabilité cruciale** → Hiérarchique obligatoire",
    category: "machine-learning",
    icon: "Layers"
  },
  {
    term: "DBSCAN (Density-Based Spatial Clustering of Applications with Noise)",
    description: "Algorithme de clustering basé sur la densité qui peut identifier des clusters de forme arbitraire et détecter les points aberrants comme du bruit.",
    category: "machine-learning",
    icon: "Layers"
  },
  {
    term: "Naive Bayes",
    description: "Naive Bayes fonctionne comme un détective qui évalue la probabilité qu'un suspect soit coupable en combinant tous les indices disponibles, en supposant (naïvement) que chaque indice est indépendant des autres. **Fondement mathématique** : applique le théorème de Bayes P(A|B) = P(B|A) × P(A) / P(B) pour calculer la probabilité d'appartenance à chaque classe. **Hypothèse 'naïve'** : toutes les features sont conditionnellement indépendantes - c'est pourquoi il est 'naïf', mais cette simplification fonctionne étonnamment bien en pratique. **Analogie médicale** : un médecin qui diagnostique en considérant chaque symptôme indépendamment (fièvre, toux, fatigue) pour calculer la probabilité de chaque maladie. **Processus** : 1) Calculer les probabilités a priori de chaque classe, 2) Calculer les vraisemblances de chaque feature, 3) Appliquer Bayes pour obtenir les probabilités a posteriori, 4) Choisir la classe avec la plus haute probabilité. **Variantes** : Gaussian (features continues), Multinomial (comptages), Bernoulli (binaire), Complement (classes déséquilibrées). **Avantages** : simplicité, rapidité, fonctionne avec peu de données, gère naturellement les classes multiples, probabilités calibrées, robuste au bruit. **Applications stars** : classification de texte (spam, sentiment), diagnostic médical, filtrage de contenu, reconnaissance de formes. **Limitations** : hypothèse d'indépendance souvent violée, sensible aux features corrélées, nécessite un lissage pour les probabilités nulles. **Performance surprenante** : malgré sa simplicité, souvent compétitif avec des algorithmes plus sophistiqués, surtout en NLP.",
    category: "machine-learning",
    icon: "Brain"
  },
  // Advanced ML Concepts
  {
    term: "Détection d'anomalies (Anomaly Detection)",
    description: "Identification des éléments ou événements rares qui diffèrent significativement de la majorité des données. Utilisée pour la détection de fraudes, surveillance système, et contrôle qualité.",
    category: "machine-learning",
    icon: "AlertTriangle"
  },
  {
    term: "Processus Gaussiens (Gaussian Processes)",
    description: "Approche non paramétrique de l'apprentissage supervisé, particulièrement puissante pour les problèmes de régression avec quantification de l'incertitude. Fournit des intervalles de confiance pour les prédictions.",
    category: "machine-learning",
    icon: "TrendingUp"
  },
  {
    term: "Apprentissage Few-shot (Few-shot Learning)",
    description: "**L'art d'apprendre avec presque rien !** Comme un étudiant brillant qui comprend un concept entier après avoir vu seulement quelques exemples, l'apprentissage few-shot permet aux modèles de maîtriser de nouvelles tâches avec un minimum de données d'entraînement.\n\n**🎯 Analogie Pédagogique :**\nImaginez apprendre à reconnaître une nouvelle race de chien après avoir vu seulement 3 photos - c'est exactement ce que fait le few-shot learning ! Contrairement à l'apprentissage traditionnel qui nécessite des milliers d'exemples.\n\n**📊 Spectre d'Apprentissage :**\n• **Zero-shot** : 0 exemple (pure généralisation)\n• **One-shot** : 1 seul exemple par classe\n• **Few-shot** : 2-10 exemples par classe\n• **Traditional** : 1000+ exemples par classe\n\n**🧠 Mécanismes Fondamentaux :**\n\n**Meta-Learning (\"Apprendre à apprendre\") :**\n- Entraînement sur de multiples tâches similaires\n- Extraction de stratégies d'apprentissage généralisables\n- Adaptation rapide aux nouvelles tâches\n\n**Transfer Learning Avancé :**\n- Réutilisation de représentations pré-entraînées\n- Fine-tuning avec régularisation forte\n- Adaptation de domaine intelligente\n\n**Metric Learning :**\n- Apprentissage d'espaces de similarité\n- Comparaison directe entre exemples\n- Classification par proximité\n\n**🛠️ Architectures Populaires :**\n- **Siamese Networks** : Comparaison de paires d'exemples\n- **Prototypical Networks** : Classification par prototype de classe\n- **MAML** : Model-Agnostic Meta-Learning\n- **Matching Networks** : Attention sur exemples de support\n\n**🎯 Applications Révolutionnaires :**\n- **Vision** : Reconnaissance d'objets rares (espèces animales)\n- **NLP** : Classification de textes dans nouveaux domaines\n- **Médecine** : Diagnostic de maladies rares\n- **Robotique** : Adaptation rapide à nouveaux environnements\n\n**⚡ Avantages Stratégiques :**\n- **Réduction drastique** des besoins en données\n- **Déploiement rapide** sur nouveaux cas d'usage\n- **Coût réduit** de collecte et annotation\n- **Adaptabilité** aux domaines spécialisés\n\n**🚨 Défis Techniques :**\n- **Overfitting** sur peu d'exemples\n- **Biais de sélection** des exemples\n- **Généralisation** limitée hors distribution\n- **Évaluation** complexe et méthodologie rigoureuse\n\n**📈 Impact Mesurable :**\nGPT-3 démontre des capacités few-shot remarquables avec 96% de précision sur des tâches jamais vues avec seulement 10 exemples. Meta's CLIP atteint 76% sur ImageNet zero-shot.",
    category: "machine-learning",
    icon: "Zap"
  },
  {
    term: "LIME (Local Interpretable Model-agnostic Explanations)",
    description: "Technique qui explique les prédictions de n'importe quel classifieur en l'approximant localement avec un modèle interprétable. Essentiel pour l'IA explicable.",
    category: "machine-learning",
    icon: "Lightbulb"
  },
  {
    term: "SHAP (SHapley Additive exPlanations)",
    description: "Approche basée sur la théorie des jeux pour expliquer la sortie de n'importe quel modèle de machine learning, en calculant la contribution de chaque caractéristique à la prédiction.",
    category: "machine-learning",
    icon: "BarChart3"
  },
  {
    term: "Théorie des graphes (Graph Theory)",
    description: "Étude des graphes, structures mathématiques utilisées pour modéliser les relations par paires entre les objets. Fondamentale pour l'analyse de réseaux sociaux, recommandations et optimisation.",
    category: "machine-learning",
    icon: "Network"
  },
  {
    term: "PageRank",
    description: "Algorithme de centralité développé par Google qui attribue un score d'importance à chaque nœud d'un graphe. Révolutionnaire pour les moteurs de recherche et l'analyse de réseaux.",
    category: "machine-learning",
    icon: "Star"
  },
  {
    term: "Attaques adverses (Adversarial Attacks)",
    description: "**L'art de tromper l'intelligence artificielle !** Comme un magicien qui utilise des illusions d'optique pour duper notre cerveau, les attaques adverses exploitent les failles des modèles ML avec des modifications invisibles à l'œil humain mais dévastatrices pour l'IA.\n\n**🎭 Analogie Visuelle :**\nImaginez un panneau STOP modifié avec des autocollants quasi-invisibles qui font qu'une voiture autonome le perçoit comme un panneau de limitation de vitesse - c'est le principe des attaques adverses !\n\n**🔍 Mécanismes d'Attaque :**\n\n**Perturbations Imperceptibles :**\n- Modification de pixels individuels (±1-5 sur 255)\n- Bruit structuré calculé mathématiquement\n- Optimisation pour maximiser l'erreur du modèle\n\n**Types d'Attaques :**\n• **White-box** : Accès complet au modèle et ses paramètres\n• **Black-box** : Accès uniquement aux prédictions\n• **Targeted** : Forcer une classe spécifique\n• **Untargeted** : Causer n'importe quelle erreur\n\n**⚔️ Techniques Populaires :**\n\n**FGSM (Fast Gradient Sign Method) :**\n- Perturbation dans la direction du gradient\n- Rapide mais moins sophistiqué\n- Efficace contre modèles linéaires\n\n**PGD (Projected Gradient Descent) :**\n- Attaque itérative plus puissante\n- Optimisation contrainte par norme L∞\n- Standard pour évaluation robustesse\n\n**C&W (Carlini & Wagner) :**\n- Optimisation sophistiquée\n- Perturbations minimales\n- Contournement des défenses\n\n**🎯 Domaines d'Impact :**\n\n**Vision par Ordinateur :**\n- Classification d'images (ImageNet)\n- Détection d'objets (YOLO, R-CNN)\n- Reconnaissance faciale\n- Conduite autonome\n\n**Traitement du Langage :**\n- Substitution de mots synonymes\n- Modification de ponctuation\n- Paraphrasing malveillant\n\n**Audio :**\n- Commandes vocales cachées\n- Transcription erronée\n- Reconnaissance de locuteur\n\n**🛡️ Méthodes de Défense :**\n\n**Adversarial Training :**\n- Entraînement avec exemples adverses\n- Amélioration de la robustesse\n- Coût computationnel élevé\n\n**Détection :**\n- Analyse statistique des entrées\n- Réseaux de neurones détecteurs\n- Métriques de confiance\n\n**Preprocessing :**\n- Débruitage des entrées\n- Compression/décompression\n- Transformations aléatoires\n\n**🚨 Implications Sécuritaires :**\n- **Véhicules autonomes** : Panneaux modifiés\n- **Sécurité** : Contournement biométrie\n- **Médical** : Diagnostic erroné\n- **Finance** : Fraude sophistiquée\n\n**📊 Statistiques Alarmantes :**\n- 99.9% des modèles ImageNet vulnérables\n- Perturbations < 0.1% des pixels suffisantes\n- Transferabilité entre modèles différents\n\n**🔬 Recherche Active :**\n- **Certified Defenses** : Garanties mathématiques\n- **Randomized Smoothing** : Robustesse probabiliste\n- **Adversarial Patches** : Attaques physiques\n- **Universal Perturbations** : Une perturbation, tous modèles\n\n**💡 Paradoxe Fondamental :**\nPlus un modèle est précis sur données normales, plus il peut être vulnérable aux attaques adverses - un compromis fondamental entre performance et robustesse.",
    category: "machine-learning",
    icon: "Shield"
  },
  {
    term: "Systèmes de recommandation (Recommender Systems)",
    description: "Prédisent la 'note' ou la 'préférence' qu'un utilisateur attribuerait à un article, utilisés dans le e-commerce, streaming, réseaux sociaux.",
    category: "machine-learning",
    icon: "Star"
  },
  {
    term: "Filtrage collaboratif (Collaborative Filtering)",
    description: "Technique de recommandation basée sur le comportement des utilisateurs similaires, utilisant les préférences collectives pour faire des recommandations.",
    category: "machine-learning",
    icon: "Users"
  }
];